{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Embedding, Conv2D, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.metrics import CosineSimilarity\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2id_path = f\"{os.getcwd()}/data/voc2id.txt\"\n",
    "sem_path = f\"{os.getcwd()}/semantic_info\"\n",
    "syn_path = f\"{sem_path}/antonyms.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/data/data.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        x = line.strip('\\n').split(' ')\n",
    "        y = x[2: int(x[0]) + 2]\n",
    "        for i in y:\n",
    "            if int(i) > 149999:\n",
    "                print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15 14 24351 24351 10 7 436 2083 26 8385 121958 4986 215 13 6932 2293 2 1|0|26 5|1|11 5|2|23 5|3|34 5|4|7 7|6|11 5|7|9 9|8|7 7|9|38 9|10|13 13|11|2 13|12|7 10|13|16 5|14|10\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2voc = dict()\n",
    "with open(voc2id_path, 'r') as file:\n",
    "    for line in file:\n",
    "        x = line.strip('\\n').split('\\t')\n",
    "        id2voc[x[1]] = x[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc2id = dict()\n",
    "with open(voc2id_path, 'r') as file:\n",
    "    for line in file:\n",
    "        x = line.strip('\\n').split('\\t')\n",
    "        voc2id[x[0]] = int(x[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism\n",
      "anarchism\n",
      "is\n",
      "a\n",
      "political\n",
      "philosophy\n",
      "that\n",
      "advocates\n",
      "self-governed\n",
      "societies\n",
      "based\n",
      "on\n",
      "voluntary\n",
      "institutions\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in y:\n",
    "    print(id2voc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = list()\n",
    "with open(syn_path, 'r') as file:\n",
    "    for line in file:\n",
    "        x = line.strip('\\n').split()\n",
    "        inds = list()\n",
    "        for i in x:\n",
    "            try: inds.append(voc2id[i])\n",
    "            except KeyError: pass\n",
    "        for i in itertools.combinations(inds, 2):\n",
    "            synonyms.append(i)\n",
    "synonyms = np.asarray(synonyms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62598, 23042],\n",
       "       [16438, 23325],\n",
       "       [12452,  1281],\n",
       "       ...,\n",
       "       [ 4169, 15863],\n",
       "       [ 2514, 72354],\n",
       "       [ 1394,   270]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticRegularizer(Regularizer):\n",
    "    def __init__(self, gamma=0.1):\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.gamma * tf.math.reduce_sum(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'gamma': float(self.gamma)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(Layer):\n",
    "    def __init__(self, vocab, dims, init_file=None):\n",
    "        \n",
    "        super(Embedding, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        self.dims = dims\n",
    "        self.init_file = init_file\n",
    "        \n",
    "        self.w = self.add_weight(shape=(self.vocab, self.dims),\n",
    "                                 initializer=\"glorot_uniform\",\n",
    "                                 trainable=True, regularizer=SemanticRegularizer())\n",
    "\n",
    "        if self.init_file != None:            \n",
    "            x = tf.Variable(initial_value=np.asarray(pd.read_csv(self.init_file, sep=' ', header=None).iloc[:, 1:], dtype=\"float32\"), \n",
    "                                 dtype=tf.float32, trainable=True)\n",
    "            self.w.assign(x)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup(self.w, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embedding(150000, 300, init_file=f\"{os.getcwd()}/embeddings/init_rand_emb.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(0, len(synonyms), size=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.gather(emb.w, synonyms[inds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = -tf.reduce_mean(tf.keras.losses.cosine_similarity(y[:, 0], y[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0004963443>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1000, 300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
